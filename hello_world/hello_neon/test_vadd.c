// 2023-04-14 10:44
#include "arm_neon.h"

static int test_vadd_s8() {
    struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{-51, 8, -16, -79, -121, -101, -47, 115},
         {-103, 43, -76, -98, -75, 79, -61, 120},
         {102, 51, -92, 79, 60, -22, -108, -21}},
        {{28, -124, -17, -117, -124, -22, 125, 109},
         {14, -125, 88, 115, -23, 119, -31, -73},
         {42, 7, 71, -2, 109, 97, 94, 36}},
        {{INT8_MAX, -47, 104, 6, 109, 57, 121, 6},
         {100, 45, -92, 25, 125, 104, -111, -103},
         {-29, -2, 12, 31, -22, -95, 10, -97}},
        {{-20, INT8_MIN, 37, 112, 106, -94, -35, 120},
         {37, 54, -20, 14, -83, -51, -59, 44},
         {17, -74, 17, 126, 23, 111, -94, -92}},
        {{-98, 45, 51, 11, 102, -84, 17, -53},
         {-38, -74, -28, 87, 30, 118, -16, 10},
         {120, -29, 23, 98, -124, 34, 1, -43}},
        {{-10, 21, 122, 97, -73, 88, -39, -36},
         {-114, -59, -21, 59, -110, -80, 103, 49},
         {-124, -38, 101, -100, 73, 8, 64, 13}},
        {{-34, -102, 60, 68, 71, 78, 15, 33},
         {4, -12, 120, 34, 106, 104, 44, 96},
         {-30, -114, -76, 102, -79, -74, 59, -127}},
        {{126, -90, -63, 53, -2, -101, 18, -116},
         {96, -3, -57, -13, -83, 47, 36, -117},
         {-34, -93, -120, 40, -85, -54, 54, 23}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(8, check, r);
    }

    return 0;
}

static int test_vaddq_s8() {
    struct {
        int8_t a[16];
        int8_t b[16];
        int8_t r[16];
    } test_vec[] = {
        {{111, -97, -90, 69, 113, 56, -115, 112, 53, -107, -44, 82, -51, -96,
          -21, -97},
         {-99, 22, 102, INT8_MIN, 111, 102, 52, -31, 89, 28, -108, -49, 112,
          -116, 125, -33},
         {12, -75, 12, -59, -32, -98, -63, 81, -114, -79, 104, 33, 61, 44, 104,
          126}},
        {{43, 35, 36, -100, 92, -78, 12, -111, 71, -32, -28, 20, -127, -49, -77,
          30},
         {-26, 25, -97, 85, INT8_MIN, -45, 54, -39, -17, -54, -88, 95, 86, 37,
          63, -126},
         {17, 60, -61, -15, -36, -123, 66, 106, 54, -86, -116, 115, -41, -12,
          -14, -96}},
        {{73, 99, 30, -91, 21, 43, 54, 92, 11, 26, 112, -116, -22, 35, -85,
          -48},
         {61, 74, 37, -67, 29, 91, -106, 12, 37, 62, 108, 124, 99, -85, -2,
          -84},
         {-122, -83, 67, 98, 50, -122, -52, 104, 48, 88, -36, 8, 77, -50, -87,
          124}},
        {{14, 28, 81, 36, 71, -120, INT8_MIN, 83, -94, -15, -33, -116, 20, -118,
          92, 81},
         {-44, -127, 14, -15, -36, -92, -2, 2, -30, 106, 126, 70, 21, 124, -14,
          35},
         {-30, -99, 95, 21, 35, 44, 126, 85, -124, 91, 93, -46, 41, 6, 78,
          116}},
        {{-104, 68, 71, -32, -52, -56, 51, 110, -71, 18, -5, -51, -99, 87, 31,
          113},
         {-39, 45, 99, -75, -46, 97, -73, -76, -53, 53, -6, -32, -79, -19, 3,
          74},
         {113, 113, -86, -107, -98, 41, -22, 34, -124, 71, -11, -83, 78, 68, 34,
          -69}},
        {{49, 75, 42, -3, 19, 93, 107, -52, 111, 102, -103, 12, -66, -72, 126,
          -105},
         {-26, -31, 76, -72, 66, 4, 108, 13, 57, 103, -19, -21, 84, -16, 53,
          -123},
         {23, 44, 118, -75, 85, 97, -41, -39, -88, -51, -122, -9, 18, -88, -77,
          28}},
        {{59, 95, -126, 78, -68, -19, 26, 43, 84, -76, 56, 18, 108, -74, -87,
          82},
         {-105, -11, 10, -39, -7, 119, -26, 51, -34, -45, 30, 50, -61, 83, -73,
          -1},
         {-46, 84, -116, 39, -75, 100, 0, 94, 50, -121, 86, 68, 47, 9, 96, 81}},
        {{-78, 57, 77, 110, 38, 104, -103, 122, 28, -47, -116, -120, -121, 53,
          -37, 30},
         {43, -27, -9, 36, 92, -35, 87, 58, -80, 117, 108, 116, -56, 35, 115,
          122},
         {-35, 30, 68, -110, -126, 69, -16, -76, -52, 70, -8, -4, 79, 88, 78,
          -104}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x16_t a = vld1q_s8(test_vec[i].a);
        int8x16_t b = vld1q_s8(test_vec[i].b);
        int8x16_t r = vaddq_s8(a, b);
        int8x16_t check = vld1q_s8(test_vec[i].r);
        ASSERT_EQUAL(16, r, check);
    }
    return 0;
}

static int test_vaddhn_s16() {
    static const struct {
        int16_t a[8];
        int16_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{10191, 527, -15725, -15434, -29291, -21715, -19795, 69},
         {-17904, -30996, 15212, -23888, -18775, 22323, -6945, -20945},
         {-31, -120, -3, 102, 68, 2, -105, -82}},
        {{15884, -24656, 26369, -27038, -28428, -23998, -30910, 21154},
         {-29119, -21032, -30263, 29264, -31937, 7881, -1944, 29901},
         {-52, 77, -16, 8, 20, -63, INT8_MAX, -57}},
        {{32055, 14355, 30180, -9778, 4101, 18555, 7575, -10086},
         {29611, 29830, -10500, 15335, -20391, -16038, 10153, -8139},
         {-16, -84, 76, 21, -64, 9, 69, -72}},
        {{18596, -30440, -6466, -15518, -8713, -29173, -22790, -23193},
         {-4839, 5401, 195, 7248, -21839, 23262, 5073, 30266},
         {53, -98, -25, -33, -120, -24, -70, 27}},
        {{21084, 6911, 24888, 12253, -5826, 14526, 9615, -22307},
         {-2542, -10819, 3575, -22287, -12360, -30462, 15587, 16383},
         {72, -16, 111, -40, -72, -63, 98, -24}},
        {{-370, -14759, 13919, -25098, -19425, -20779, -19751, -5290},
         {5033, -24384, -20191, -9912, 19073, 25698, 25222, 5283},
         {18, 103, -25, 119, -2, 19, 21, -1}},
        {{-928, -16166, -12238, 21085, 13188, 23808, 22501, -29112},
         {2154, -29906, 30394, 15204, -14400, 18079, 16937, -30374},
         {4, 76, 70, -115, -5, -93, -102, 23}},
        {{13630, 28745, -22779, -30014, -15398, -16409, 12314, -31666},
         {31800, -3568, 29939, -19667, -13253, 25850, 21518, 19694},
         {-79, 98, 27, 61, -112, 36, -124, -47}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int16x8_t a = vld1q_s16(test_vec[i].a);
        int16x8_t b = vld1q_s16(test_vec[i].b);
        int8x8_t r = vaddhn_s16(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(8, r, check);
    }
    return 0;
}

static int test_vhadd_s8() {
    static const struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{-111, -110, 14, -92, -21, -15, -67, 34},
         {85, 113, 87, -58, 112, 51, -18, 103},
         {-13, 1, 50, -75, 45, 18, -43, 68}},
        {{119, -32, -32, -30, -5, -80, -127, 47},
         {-27, -10, -111, -68, 125, -43, -31, 14},
         {46, -21, -72, -49, 60, -62, -79, 30}},
        {{103, -17, -78, 83, -32, 112, 117, 53},
         {-31, -52, -4, 81, -1, -22, -72, 118},
         {36, -35, -41, 82, -17, 45, 22, 85}},
        {{-54, -104, 89, -59, 73, -38, -12, 46},
         {-48, -123, -22, 78, 90, -53, 92, -63},
         {-51, -114, 33, 9, 81, -46, 40, -9}},
        {{-70, 15, 20, -101, INT8_MAX, -119, -48, 96},
         {85, -52, -79, 84, -74, 106, -53, INT8_MIN},
         {7, -19, -30, -9, 26, -7, -51, -16}},
        {{2, 36, 69, 75, -2, 57, 121, -50},
         {-66, 99, 28, 24, 46, 121, -38, -23},
         {-32, 67, 48, 49, 22, 89, 41, -37}},
        {{-120, -18, -124, 7, 120, 84, 103, -51},
         {33, 24, 34, -41, -126, -19, 88, -123},
         {-44, 3, -45, -17, -3, 32, 95, -87}},
        {{17, -99, -48, 15, -41, 74, -35, -107},
         {-83, -6, -82, -36, 115, -120, -59, -5},
         {-33, -53, -65, -11, 37, -23, -47, -56}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vhadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(8, r, check);
    }
    return 0;
}

static int test_vrhadd_s8() {
    static const struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{36, -29, -56, 59, -57, -47, 80, -118},
         {67, 70, 3, -93, 56, -95, -31, -57},
         {52, 21, -26, -17, 0, -71, 25, -87}},
        {{122, -28, 39, -51, 36, 123, -105, -67},
         {-33, 123, -90, -110, -50, -124, -64, -14},
         {45, 48, -25, -80, -7, 0, -84, -40}},
        {{103, -119, 45, 46, 90, 125, -72, -99},
         {-61, -69, 64, -5, 92, 34, -62, -42},
         {21, -94, 55, 21, 91, 80, -67, -70}},
        {{6, -22, -92, 42, 101, 59, -25, 68},
         {-74, -114, -42, -124, 18, -105, 119, 121},
         {-34, -68, -67, -41, 60, -23, 47, 95}},
        {{32, -92, -89, 122, 34, 96, 24, -27},
         {27, 88, -31, 120, 122, -93, 78, -127},
         {30, -2, -60, 121, 78, 2, 51, -77}},
        {{-115, -14, -85, -13, 45, -109, 55, -29},
         {33, 14, 104, 51, -91, -33, -84, -59},
         {-41, 0, 10, 19, -23, -71, -14, -44}},
        {{-125, 83, 63, -91, -77, 87, -117, -49},
         {-80, 108, 71, 42, 15, -107, -85, -99},
         {-102, 96, 67, -24, -31, -10, -101, -74}},
        {{-120, 87, -112, -75, -22, -57, -103, 11},
         {-43, 1, 62, 122, -32, -22, 63, 99},
         {-81, 44, -25, 24, -27, -39, -20, 55}},

    };
    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vrhadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(8, r, check);
    }
    return 0;
}

static int test_vqadd_s8() {
    static const struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{-88, -39, -126, -86, -106, -49, 70, 124},
         {64, -91, 64, 47, 38, 91, -80, -15},
         {-24, INT8_MIN, -62, -39, -68, 42, -10, 109}},
        {{-18, -104, 112, 14, 66, 72, -83, -71},
         {-106, -119, 15, -10, 78, 70, INT8_MAX, -9},
         {-124, INT8_MIN, INT8_MAX, 4, INT8_MAX, INT8_MAX, 44, -80}},
        {{31, 1, -95, -74, -48, -25, 50, 16},
         {-116, 114, 64, -78, -51, -16, -93, -69},
         {-85, 115, -31, INT8_MIN, -99, -41, -43, -53}},
        {{-119, 19, -54, -53, 92, 119, -124, -14},
         {0, -109, -23, 79, -39, 104, 70, -7},
         {-119, -90, -77, 26, 53, INT8_MAX, -54, -21}},
        {{105, -25, -81, 58, -50, -31, 74, 90},
         {83, -118, 12, 32, 123, -80, -37, 4},
         {INT8_MAX, INT8_MIN, -69, 90, 73, -111, 37, 94}},
        {{-61, -91, -49, 31, 29, 83, 18, 29},
         {-25, -5, 108, -64, 99, -78, -71, -52},
         {-86, -96, 59, -33, INT8_MAX, 5, -53, -23}},
        {{-103, 104, 6, 103, 73, 81, -63, -100},
         {-37, -50, -68, 86, 126, -104, 90, 65},
         {INT8_MIN, 54, -62, INT8_MAX, INT8_MAX, -23, 27, -35}},
        {{61, 41, 97, 90, 125, 115, 120, 100},
         {110, -28, 36, -47, -105, -34, -99, 48},
         {INT8_MAX, 13, INT8_MAX, 43, 20, 81, 21, INT8_MAX}},
    };

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vqadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(8, r, check)
    }
    return 0;
}

int main(int argc, char *argv[]) {
    test_vadd_s8();
    test_vaddq_s8();
    test_vhadd_s8();
    test_vrhadd_s8();
    test_vqadd_s8();
    return 0;
}
